{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdapterTrainer' from 'transformers' (/Users/blake/miniforge3/envs/fast/lib/python3.9/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpynvml\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTAdapter\n",
      "File \u001b[0;32m~/Documents/TECH/research/projectx/fast/fast/utils/adapter.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, AdapterTrainer, logging\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertAdapterModel\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBERTAdapter\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdapterTrainer' from 'transformers' (/Users/blake/miniforge3/envs/fast/lib/python3.9/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pathlib\n",
    "import csv\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from collections import namedtuple\n",
    "\n",
    "import threading\n",
    "import pynvml\n",
    "from utils.adapter import BERTAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"  # default device is CPU\n",
    "if torch.cuda.is_available():\n",
    "    # I read that this works for detecting if notebook is being run in a colab environment, not sure though\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        print(\"colab environment\")\n",
    "        device_name = \"gpu\" \n",
    "    else:\n",
    "        device_name = \"cuda\" # CUDA for NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = torch.device(\"mps\")  # Metal Performance Shaders for Apple M-series GPU\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_param = \"cola\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_type: [\"one\", \"two\"]\n",
    "# class_type: [\"BC\", \"MC\", \"R\"]\n",
    "# input_size: int (represents input size of feedforward, aka embedding size)\n",
    "# col_names: column names of relavent sentences on hugging face\n",
    "# num_classes needs to be 1 for BC and R, only change value to number of classes for MC\n",
    "\n",
    "TaskConfig = namedtuple(\"TaskConfig\", [\"sentence_type\", \"class_type\", \"num_classes\", \"input_size\", \"col_names\"])\n",
    "\n",
    "task_configs = {\n",
    "    \"cola\": TaskConfig(\"one\", \"BC\", 1, 768, ['sentence']),\n",
    "    \"sst2\": TaskConfig(\"one\", \"BC\", 1, 768, ['sentence']),\n",
    "    \"mrpc\": TaskConfig(\"two\", \"BC\", 1, 768, ['sentence1', 'sentence2']),\n",
    "    \"stsb\": TaskConfig(\"two\", \"R\", 1, 768, ['sentence1', 'sentence2']),\n",
    "    \"qqp\": TaskConfig(\"two\", \"BC\", 1, 768, ['question1', 'question2']),\n",
    "    \"mnli_matched\": TaskConfig(\"two\", \"MC\", 3, 768, ['premise', 'hypothesis']),\n",
    "    \"mnli_mismatched\": TaskConfig(\"two\", \"MC\", 3, 768, ['premise', 'hypothesis']),\n",
    "    \"qnli\": TaskConfig(\"two\", \"BC\", 1, 768, ['question', 'sentence']),\n",
    "    \"rte\": TaskConfig(\"two\", \"BC\", 1, 768, ['sentence1', 'sentence2']),\n",
    "    \"wnli\": TaskConfig(\"two\", \"BC\", 1, 768, ['sentence1', 'sentence2']),\n",
    "}\n",
    "\n",
    "task_config = task_configs[task_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_param == \"mnli_matched\": \n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_matched\"\n",
    "    test_key = \"test_matched\"\n",
    "elif task_param == \"mnli_mismatched\":\n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_mismatched\"\n",
    "    test_key = \"test_mismatched\"\n",
    "else:\n",
    "    data = load_dataset(\"glue\", task_param)\n",
    "    val_key = \"validation\"\n",
    "    test_key = \"test\"\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[\"train\"]\n",
    "y = \"label\"\n",
    "X_val = data[val_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_param_grid = {\n",
    "    'num_epochs': [50],\n",
    "    'batch_size': [32, 512],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'category': [task_config.class_type],\n",
    "    'device': [device_name]\n",
    "}\n",
    "\n",
    "# Create a list of all combinations of hyperparameters\n",
    "adapter_params = [dict(zip(adapter_param_grid.keys(), v)) for v in itertools.product(*adapter_param_grid.values())]\n",
    "print(f\"{len(adapter_params)} hyperparameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for saving power outputs\n",
    "results_folder = pathlib.Path(f\"results/adapter/{task_param}\")\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_file_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = results_folder / f\"val_{save_file_id}.csv\"\n",
    "with open(results_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['power', 'time'])\n",
    "print(f\"saving results to ./{results_file}\")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "adapter_bar = tqdm(enumerate(adapter_params), total=len(adapter_params))\n",
    "for i, params in adapter_bar:\n",
    "    # Formatting params to display\n",
    "    print_params = params.copy()\n",
    "    for param in ['category', 'device']:\n",
    "        del print_params[param]\n",
    "\n",
    "    # Initialize the model with current set of hyperparameters\n",
    "    adapter = BERTAdapter(**params)\n",
    "\n",
    "    # Create a thread for tracking power output (NVIDIA ONLY), logs power and time\n",
    "    def get_power():\n",
    "        pynvml.nvmlInit()\n",
    "        while not adapter.train_stop_flag:\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # Returns device handle, index 0 specifies the first GPU\n",
    "            power = pynvml.nvmlDeviceGetPowerUsage(handle)  # Retrieves power usage for GPU in milliwatts\n",
    "            power = power / 1000  # convert mW to W\n",
    "            curr_time = time.time()\n",
    "            print(\"Current NVIDIA power output:\", power, \"at time\", curr_time)\n",
    "            # Write to results csv\n",
    "            with open(results_file, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([power, curr_time])\n",
    "                \n",
    "        pynvml.nvmlShutdown()\n",
    "        \n",
    "    power_thread = threading.Thread(target=get_power)\n",
    "\n",
    "    # Make sure power output was recorded in the correct time range\n",
    "    print(\"Start time:\", time.time()) \n",
    "\n",
    "    power_thread.start()  # Start the benchmarking thread\n",
    "    metrics, train_times_per_epoch, energy_per_epoch = adapter.fit(X_train, y, X_val, y)\n",
    "    power_thread.join()  # Wait for the thread to complete\n",
    "        \n",
    "    print(\"End time:\", time.time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
