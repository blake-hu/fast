{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST: Feedforward-ASsisted Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for running GLUE tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pathlib\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from utils.feed_forward import FeedForward\n",
    "from utils.cls import extract_cls_embeddings\n",
    "from utils.mean_pooling import mean_pooling\n",
    "from utils.energy import get_energy\n",
    "from utils.embeddings import add_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Python environment variables for CUBLAS (NVIDIA)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ['CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "# Standardized default seed\n",
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"  # Default device is CPU\n",
    "if torch.cuda.is_available():\n",
    "    # I read that this works for detecting if notebook is being run in a colab environment, not sure though\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        print(\"colab environment\")\n",
    "        device_name = \"gpu\" \n",
    "    else:\n",
    "        device_name = \"cuda\" # CUDA for NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = torch.device(\"mps\")  # Metal Performance Shaders for Apple M-series GPU\n",
    "\n",
    "# device_name = \"cuda:0\"\n",
    "device = torch.device(device_name)\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to set:\n",
    "- Model\n",
    "    - MPNet\n",
    "    - DistilRoBERTa\n",
    "- Task\n",
    "    - cola\n",
    "    - sst2\n",
    "    - mrpc\n",
    "    - stsb\n",
    "    - qqp\n",
    "    - mnli_matched\n",
    "    - mnli_mismatched\n",
    "    - qnli\n",
    "    - rte\n",
    "    - wnli\n",
    "- Embedding type\n",
    "    - Single Sentence\n",
    "        - cls\n",
    "        - meanpool\n",
    "        - sentence\n",
    "    - Two Sentence\n",
    "        - Each sentence separately\n",
    "            - cls_single\n",
    "            - meanpool_single\n",
    "        - Both sentences at once\n",
    "            - cls_double\n",
    "            - meanpool_double\n",
    "        - sentence_single (no sentence_double option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = \"DistilRoBERTa\"\n",
    "task_param = \"mrpc\"\n",
    "embedding_param = [\"meanpool_single\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_param == \"MPNet\":\n",
    "\n",
    "    if \"cls\" in \"_\".join(embedding_param) or \"meanpool\" in \"_\".join(embedding_param):\n",
    "        from transformers import MPNetTokenizer, MPNetModel\n",
    "        tokenizer = MPNetTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "        model = MPNetModel.from_pretrained(\"microsoft/mpnet-base\").to(device)\n",
    "        \n",
    "    if \"sentence\" in \"_\".join(embedding_param):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        sentence_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2').to(device)\n",
    "\n",
    "elif model_param == \"DistilRoBERTa\":\n",
    "\n",
    "    if \"cls\" in \"_\".join(embedding_param) or \"meanpool\" in \"_\".join(embedding_param):\n",
    "        from transformers import RobertaTokenizer, RobertaModel\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
    "        model = RobertaModel.from_pretrained('distilroberta-base').to(device)\n",
    "\n",
    "    if \"sentence\" in \"_\".join(embedding_param):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        sentence_model = SentenceTransformer('sentence-transformers/all-distilroberta-v1').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskConfig = namedtuple(\"TaskConfig\", [\"sentence_type\", \"class_type\", \"num_classes\", \"col_names\"])\n",
    "\n",
    "task_configs = {\n",
    "    \"cola\": TaskConfig(\"one\", \"BC\", 1, ['sentence']),\n",
    "    \"sst2\": TaskConfig(\"one\", \"BC\", 1, ['sentence']),\n",
    "    \"mrpc\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "    \"stsb\": TaskConfig(\"two\", \"R\", 1, ['sentence1', 'sentence2']),\n",
    "    \"qqp\": TaskConfig(\"two\", \"BC\", 1, ['question1', 'question2']),\n",
    "    \"mnli_matched\": TaskConfig(\"two\", \"MC\", 3, ['premise', 'hypothesis']),\n",
    "    \"mnli_mismatched\": TaskConfig(\"two\", \"MC\", 3, ['premise', 'hypothesis']),\n",
    "    \"qnli\": TaskConfig(\"two\", \"BC\", 1, ['question', 'sentence']),\n",
    "    \"rte\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "    \"wnli\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "}\n",
    "\n",
    "task_config = task_configs[task_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if task_param == \"mnli_matched\": \n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_matched\"\n",
    "    test_key = \"test_matched\"\n",
    "elif task_param == \"mnli_mismatched\":\n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_mismatched\"\n",
    "    test_key = \"test_mismatched\"\n",
    "else:\n",
    "    data = load_dataset(\"glue\", task_param)\n",
    "    val_key = \"validation\"\n",
    "    test_key = \"test\"\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(data[\"train\"][\"label\"])\n",
    "Y_val = np.array(data[val_key][\"label\"])\n",
    "Y_test = np.array(data[test_key][\"label\"])\n",
    "\n",
    "if task_config.class_type == \"MC\":\n",
    "    Y_train = np.reshape(Y_train, (-1, 1))\n",
    "    Y_val = np.reshape(Y_val, (-1, 1))\n",
    "    Y_test = np.reshape(Y_test, (-1, 1))\n",
    "    \n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(Y_train)\n",
    "    print(ohe.categories_)\n",
    "     \n",
    "    Y_train = ohe.transform(Y_train)\n",
    "    Y_val = ohe.transform(Y_val)\n",
    "    Y_test = ohe.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanpool_single embeddings found!\n",
      "X_train shape: (3668, 1536)\n",
      "X_val shape  : (408, 1536)\n",
      "X_test shape : (1725, 1536)\n"
     ]
    }
   ],
   "source": [
    "total_length = len(embedding_param)\n",
    "\n",
    "X_train, X_val, X_test, embedding_tracker = [None]*total_length, [None]*total_length, [None]*total_length, []\n",
    "create_dataloader, create_sentence = False, False\n",
    "\n",
    "for id, embedding in enumerate(embedding_param):\n",
    "    \n",
    "    cache_path = pathlib.Path(f\"./cache/{embedding}/{task_param}\")\n",
    "    cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_names = ['X_train', 'X_val', 'X_test'] \n",
    "    paths = [pathlib.Path(cache_path / f\"{f}_{model_param}.npy\") for f in file_names]\n",
    "\n",
    "    if all(path.exists() for path in paths):\n",
    "        print(f\"{embedding} embeddings found!\")\n",
    "        X_train[id] = np.load(paths[0])\n",
    "        X_val[id] = np.load(paths[1])\n",
    "        X_test[id] = np.load(paths[2])\n",
    "\n",
    "        print(f\"X_train shape: {X_train[0].shape}\")\n",
    "        print(f\"X_val shape  : {X_val[0].shape}\")\n",
    "        print(f\"X_test shape : {X_test[0].shape}\")\n",
    "\n",
    "    else:\n",
    "        embedding_tracker.append(id)\n",
    "        print(f\"No {embedding} saved embeddings found\")\n",
    "\n",
    "        if \"cls\" in embedding_param[id] or \"meanpool\" in embedding_param[id]:\n",
    "            create_dataloader = True\n",
    "        elif \"sentence\" in embedding_param[id]:\n",
    "            create_sentence = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenization functions\n",
    "max_len=512\n",
    "\n",
    "def tokenize(examples, name):\n",
    "    tokenized = tokenizer(examples[task_config.col_names[0]],\n",
    "                          add_special_tokens=True,\n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          max_length=max_len,\n",
    "                          return_tensors='pt')\n",
    "    return {name + \"_\" + key: value.to(device) for key, value in tokenized.items()}\n",
    "\n",
    "def tokenize_single(examples, name):\n",
    "    tokenized_1 = tokenizer(examples[task_config.col_names[0]],\n",
    "                         add_special_tokens=True,\n",
    "                         padding='max_length',\n",
    "                         truncation=True,\n",
    "                         max_length=max_len,\n",
    "                         return_tensors='pt')\n",
    "    tokenized_2 = tokenizer(examples[task_config.col_names[1]],\n",
    "                         add_special_tokens=True,\n",
    "                         padding='max_length',\n",
    "                         truncation=True,\n",
    "                         max_length=max_len,\n",
    "                         return_tensors='pt')\n",
    "    \n",
    "    tokenized_output = {name + \"_\" + key + \"_1\": value.to(device) for key, value in tokenized_1.items()}\n",
    "    tokenized_output.update({name + \"_\" + key + \"_2\": value.to(device) for key, value in tokenized_2.items()})\n",
    "    return tokenized_output\n",
    "\n",
    "def tokenize_double(examples, name):\n",
    "    tokenized = tokenizer(examples[task_config.col_names[0]],\n",
    "                          examples[task_config.col_names[1]],\n",
    "                          add_special_tokens=True,\n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          max_length=max_len,\n",
    "                          return_tensors='pt')\n",
    "    return {name + \"_\" + key: value.to(device) for key, value in tokenized.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for id, embedding in enumerate(embedding_param):\n",
    "    if id in embedding_tracker and \"sentence\" not in embedding:\n",
    "        if \"single\" in embedding:\n",
    "            inputs.append(data.map(lambda examples: tokenize_single(examples, name=embedding), batched=True))\n",
    "        elif \"double\" in embedding:\n",
    "            inputs.append(data.map(lambda examples: tokenize_double(examples, name=embedding), batched=True))\n",
    "        else:\n",
    "            inputs.append(data.map(lambda examples: tokenize(examples, name=embedding), batched=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 128\n",
    "\n",
    "if create_dataloader:\n",
    "    from utils.dataloader import TransformerDataset, clean_dataset\n",
    "    \n",
    "    # Merge datasets for each split and convert to PyTorch datasets\n",
    "    train_df = clean_dataset(inputs, 'train')\n",
    "    validation_df = clean_dataset(inputs, 'validation')\n",
    "    test_df = clean_dataset(inputs, 'test')\n",
    "\n",
    "    # Create dataset instances\n",
    "    train_dataset = TransformerDataset(train_df)\n",
    "    validation_dataset = TransformerDataset(validation_df)\n",
    "    test_dataset = TransformerDataset(test_df)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding/sentence functions\n",
    "def compute_embeddings(loader, X):\n",
    "    column_names = list(next(iter(loader)).keys())\n",
    "\n",
    "    # Creating pairs of input IDs and attention masks\n",
    "    pairs = []\n",
    "    for name in column_names:\n",
    "        if 'input_ids' in name:\n",
    "            mask_name = name.replace('input_ids', 'attention_mask')\n",
    "            pairs.append((name, mask_name))\n",
    "\n",
    "    # Loop over each pair of input ID and attention mask\n",
    "    for input_id_name, mask_name in pairs:\n",
    "        embedding = []\n",
    "        tqdm.write(f\"{input_id_name} {mask_name}\")\n",
    "        # time.sleep(0.2) # tqdm prints weird without slight time delay (will make embedding time inaccurate)\n",
    "        \n",
    "        for input_embedding in tqdm(loader):\n",
    "            # Move batch to device\n",
    "            model.eval()\n",
    "            input_embedding = {key: value.to(device) for key, value in input_embedding.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_embedding[input_id_name], attention_mask=input_embedding[mask_name])\n",
    "\n",
    "                if \"cls\" in input_id_name:\n",
    "                    embed = extract_cls_embeddings(outputs)\n",
    "                elif \"meanpool\" in input_id_name:\n",
    "                    embed = mean_pooling(outputs, input_embedding[mask_name])\n",
    "\n",
    "            embedding.append(embed.cpu().numpy())\n",
    "\n",
    "        id = embedding_param.index(input_id_name.split(\"_input_ids\")[0])\n",
    "        # print(id)\n",
    "        if \"2\" in input_id_name:\n",
    "            U, V = X[id], np.concatenate(embedding, axis=0)\n",
    "            X[id] = np.hstack([U, V])\n",
    "            # print(X[id])\n",
    "        else:\n",
    "            X[id] = np.concatenate(embedding, axis=0)\n",
    "            # print(X[id])\n",
    "\n",
    "def compute_sentence(sentences):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        batch_embeddings = sentence_model.encode(batch_sentences)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: Using default time tracking\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding: Using default time tracking\")\n",
    "# Track time\n",
    "start_time = time.time()\n",
    "\n",
    "if create_dataloader: # Compute CLS/Meanpool embeddings\n",
    "    compute_embeddings(train_loader, X_train)\n",
    "    compute_embeddings(validation_loader, X_val)\n",
    "    compute_embeddings(test_loader, X_test)\n",
    "if create_sentence: # Compute Sentence embeddings\n",
    "    if \"sentence_single\" in embedding_param:\n",
    "        id = embedding_param.index(\"sentence_single\")\n",
    "        U_train, V_train = compute_sentence(data[\"train\"][task_config.col_names[0]]), compute_sentence(data[\"train\"][task_config.col_names[1]])\n",
    "        U_val, V_val = compute_sentence(data[\"validation\"][task_config.col_names[0]]), compute_sentence(data[\"validation\"][task_config.col_names[1]])\n",
    "        U_test, V_test = compute_sentence(data[\"test\"][task_config.col_names[0]]), compute_sentence(data[\"test\"][task_config.col_names[1]])\n",
    "\n",
    "        X_train[id] = np.hstack([U_train, V_train])\n",
    "        X_val[id] = np.hstack([U_val, V_val])\n",
    "        X_test[id] = np.hstack([U_test, V_test])\n",
    "\n",
    "    elif \"sentence\" in embedding_param:\n",
    "        id = embedding_param.index(\"sentence\")\n",
    "        X_train[id] = compute_sentence(data[\"train\"][task_config.col_names[0]])\n",
    "        X_val[id] = compute_sentence(data[\"validation\"][task_config.col_names[0]])\n",
    "        X_test[id] = compute_sentence(data[\"test\"][task_config.col_names[0]])\n",
    "\n",
    "embedding_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embeddings to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in embedding_tracker:\n",
    "\n",
    "    cache_path = pathlib.Path(f\"./cache/{embedding_param[id]}/{task_param}\")\n",
    "    cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_names = ['X_train', 'X_val', 'X_test']\n",
    "    paths = [pathlib.Path(cache_path / f\"{f}_{model_param}.npy\") for f in file_names]\n",
    "\n",
    "    with open(paths[0], 'wb') as X_train_file:\n",
    "        np.save(X_train_file, X_train[id])\n",
    "    with open(paths[1], 'wb') as X_val_file:\n",
    "        np.save(X_val_file, X_val[id])\n",
    "    with open(paths[2], 'wb') as X_test_file:\n",
    "        np.save(X_test_file, X_test[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3668, 1536)\n",
      "X_val shape  : (408, 1536)\n",
      "X_test shape : (1725, 1536)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_val = np.concatenate(X_val, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape  : {X_val.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668, 768)\n",
      "(408, 768)\n",
      "(1725, 768)\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Choose ids of (Ux, Vx) to alter embeddings\n",
    "column_ids = [] if task_config.sentence_type == \"one\" else [0]\n",
    "######################\n",
    "if column_ids:\n",
    "    f = lambda embeddings : add_embeddings(embeddings=embeddings, column_ids=column_ids, embedding_size=768, \n",
    "                                           is_UV=[False], is_diff=[True], is_mult=[False], use_abs=[True])\n",
    "\n",
    "    X_train_computed = f(embeddings=X_train)\n",
    "    X_val_computed = f(embeddings=X_val)\n",
    "    X_test_computed = f(embeddings=X_test)\n",
    "else:\n",
    "    X_train_computed = X_train\n",
    "    X_val_computed = X_val\n",
    "    X_test_computed = X_test\n",
    "    \n",
    "print(X_train_computed.shape)\n",
    "print(X_val_computed.shape)\n",
    "print(X_test_computed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hyperparameter combinations\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_computed.shape[1]\n",
    "\n",
    "param_grid = {\n",
    "    'max_epochs': [50],\n",
    "    'batch_size': [32],\n",
    "    'learning_rate': [0.001],\n",
    "    'category': [task_config.class_type],\n",
    "    'norm': [False],\n",
    "    'input_size': [768],\n",
    "    'layer_size': [2],\n",
    "    'num_classes': [task_config.num_classes],\n",
    "    'num_layers': [1],\n",
    "    'weight_decay': [0.0001],\n",
    "    'patience': [3],\n",
    "    'min_delta': [0],\n",
    "}\n",
    "\n",
    "# default overrides\n",
    "param_grid['verbose'] = [True]\n",
    "param_grid['device'] = [device_name]\n",
    "param_grid['category'] = [task_config.class_type]\n",
    "param_grid['num_classes'] = [task_config.num_classes]\n",
    " \n",
    "# Create a list of all combinations of hyperparameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "print(f\"{len(all_params)} hyperparameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results to ./../../fast-results/results/meanpool_single/mrpc/val_20240213_154310_DistilRoBERTa.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584a5404f0274df297f549d7d8979bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'FeedForward' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Initialize the model with current set of hyperparameters\u001b[39;00m\n\u001b[1;32m     47\u001b[0m feed_forward \u001b[38;5;241m=\u001b[39m FeedForward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 48\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m metrics, train_times_per_epoch, energy_per_epoch \u001b[38;5;241m=\u001b[39m feed_forward\u001b[38;5;241m.\u001b[39mfit(X_train_computed,\n\u001b[1;32m     51\u001b[0m                                                                     Y_train,\n\u001b[1;32m     52\u001b[0m                                                                     X_val_computed,\n\u001b[1;32m     53\u001b[0m                                                                     Y_val)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Log average training time per epoch for current parameter set\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Note: FFN frequently stops early\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/fast/lib/python3.9/site-packages/torchinfo/torchinfo.py:212\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     cache_forward_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43mget_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    214\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n",
      "File \u001b[0;32m~/miniforge3/envs/fast/lib/python3.9/site-packages/torchinfo/torchinfo.py:481\u001b[0m, in \u001b[0;36mget_device\u001b[0;34m(model, input_data)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 481\u001b[0m         model_parameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m())\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         model_parameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeedForward' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "# Setup for logging\n",
    "console_output_filename = f'./output/{\"_\".join(embedding_param[0])}_{task_param}_console_output.txt'\n",
    "\n",
    "with open(console_output_filename, 'a') as logfile:\n",
    "    logfile.write('\\n\\nBEGIN TRAINING LOOP\\n\\n')\n",
    "\n",
    "# Setup for saving results\n",
    "results_folder = pathlib.Path(f\"../../fast-results/results/{embedding_param[0]}/{task_param}\")\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_file_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = results_folder / f\"val_{save_file_id}_{model_param}.csv\"\n",
    "\n",
    "# different metrics are recorded for classification vs regression tasks\n",
    "if task_config.class_type in [\"BC\", \"MC\"]:\n",
    "    metric_types = ['mcc', 'f1', 'accuracy']\n",
    "elif task_config.class_type == \"R\":\n",
    "    metric_types = ['pearson', 'spearman']\n",
    "\n",
    "with open(results_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    header = metric_types + ['num_epochs', 'training time / epoch', 'embedding time', 'training energy / epoch', 'embedding energy'] + list(all_params[0].keys())\n",
    "    writer.writerow(header)\n",
    "print(f\"saving results to ./{results_file}\")\n",
    "metric_types += [\"epoch\"]\n",
    "# Saves best accuracy for progress bar display\n",
    "display_best = float(\"-inf\")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "bar = tqdm(enumerate(all_params), total=len(all_params))\n",
    "for i, params in bar:\n",
    "    # Formatting params to display\n",
    "    print_params = params.copy()\n",
    "    for param in ['category', 'device']:\n",
    "        del print_params[param]\n",
    "        \n",
    "    # reset torch so that results are consistent\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Initialize the model with current set of hyperparameters\n",
    "    feed_forward = FeedForward(**params)\n",
    "    summary(feed_forward, input_size=(param_grid['input_size'],))\n",
    "\n",
    "    metrics, train_times_per_epoch, energy_per_epoch = feed_forward.fit(X_train_computed,\n",
    "                                                                        Y_train,\n",
    "                                                                        X_val_computed,\n",
    "                                                                        Y_val)\n",
    "    \n",
    "    # Log average training time per epoch for current parameter set\n",
    "    # Note: FFN frequently stops early\n",
    "    training_time = np.mean(train_times_per_epoch)\n",
    "    training_energy = np.mean(energy_per_epoch) \n",
    "    # Compute energy for embedding generation\n",
    "    embedding_energy = get_energy(embedding_time, device) # This method effectively just computes energy for a given time\n",
    "\n",
    "    metric_vals = [metrics[mt] for mt in metric_types]\n",
    "    \n",
    "    # displaying results in progress bar\n",
    "    display_recent = metrics[\"pearson\" if task_config.class_type == \"R\" else \"accuracy\"]\n",
    "    display_best = max(display_best, display_recent)\n",
    "    bar.set_description(f\"Best: {display_best:.5f}, Last: {display_recent:.5f}\")\n",
    "\n",
    "    # Write stats to log file\n",
    "    with open(console_output_filename, 'a') as logfile:\n",
    "        logfile.write(f\"\\n\\nTraining with parameters:\\n{print_params}\")\n",
    "        logfile.write(f\"\\nEarly stopped on epoch: {metrics['epoch']}\")\n",
    "        for name, val in zip(metric_types, metric_vals):\n",
    "            logfile.write(f\"\\nValidation {name}: {val}\")\n",
    "        logfile.write(f\"\\nTraining time      : {training_time}\") \n",
    "        logfile.write(f\"\\nEmbedding time     : {embedding_time}\") \n",
    "        logfile.write(f\"\\nTraining energy    : {training_energy}\") \n",
    "        logfile.write(f\"\\nEmbedding energy   : {embedding_energy}\") \n",
    "    # Write to results csv\n",
    "    with open(results_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        row = metric_vals + [training_time, embedding_time, training_energy, embedding_energy] + list(params.values())\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>training time / epoch</th>\n",
       "      <th>embedding time</th>\n",
       "      <th>training energy / epoch</th>\n",
       "      <th>embedding energy</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>norm</th>\n",
       "      <th>input_size</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>patience</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>verbose</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56338</td>\n",
       "      <td>0.56338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219094</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>16.432066</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>mps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcc       f1  accuracy  num_epochs  training time / epoch  embedding time  \\\n",
       "0  0.0  0.56338   0.56338           1               0.219094        0.000485   \n",
       "\n",
       "   training energy / epoch  embedding energy  max_epochs  batch_size  ...  \\\n",
       "0                16.432066          0.036371          50          32  ...   \n",
       "\n",
       "    norm input_size  layer_size  num_classes  num_layers  weight_decay  \\\n",
       "0  False        768         768            1           1        0.0001   \n",
       "\n",
       "   patience  min_delta  verbose  device  \n",
       "0         3          0     True     mps  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(results_file)\n",
    "if task_config.class_type in [\"BC\", \"MC\"]:\n",
    "    print_metric = \"accuracy\"\n",
    "elif task_config.class_type == \"R\":\n",
    "    print_metric = \"pearson\"\n",
    "\n",
    "best = results_df[print_metric].max()\n",
    "best_row = results_df[results_df[print_metric] == best]\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>training time / epoch</th>\n",
       "      <th>embedding time</th>\n",
       "      <th>training energy / epoch</th>\n",
       "      <th>embedding energy</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>norm</th>\n",
       "      <th>input_size</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>patience</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>verbose</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56338</td>\n",
       "      <td>0.56338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219094</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>16.432066</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>mps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcc       f1  accuracy  num_epochs  training time / epoch  embedding time  \\\n",
       "0  0.0  0.56338   0.56338           1               0.219094        0.000485   \n",
       "\n",
       "   training energy / epoch  embedding energy  max_epochs  batch_size  ...  \\\n",
       "0                16.432066          0.036371          50          32  ...   \n",
       "\n",
       "    norm input_size  layer_size  num_classes  num_layers  weight_decay  \\\n",
       "0  False        768         768            1           1        0.0001   \n",
       "\n",
       "   patience  min_delta  verbose  device  \n",
       "0         3          0     True     mps  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
