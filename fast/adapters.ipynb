{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST: Feedforward-ASsisted Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for running GLUE tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pathlib\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from adapters import AutoAdapterModel\n",
    "\n",
    "from utils.feed_forward import FeedForward\n",
    "from utils.cls import extract_cls_embeddings\n",
    "from utils.mean_pooling import mean_pooling\n",
    "from utils.energy import get_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUBLAS_WORKSPACE_CONFIG\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # or \":16:8\"\n",
    "os.environ['CUDNN_DETERMINISTIC'] = '1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Standardized default seed\n",
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cpu\"  # default device is CPU\n",
    "if torch.cuda.is_available():\n",
    "    # I read that this works for detecting if notebook is being run in a colab environment, not sure though\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        print(\"colab environment\")\n",
    "        device_name = \"gpu\" \n",
    "    else:\n",
    "        device_name = \"cuda:0\" # CUDA for NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = torch.device(\"mps\")  # Metal Performance Shaders for Apple M-series GPU\n",
    "\n",
    "# device_name = \"cuda:0\"\n",
    "device = torch.device(device_name)\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Parameters:\n",
    "- cola\n",
    "- sst2\n",
    "- mrpc\n",
    "- stsb\n",
    "- qqp\n",
    "- mnli_matched\n",
    "- mnli_mismatched\n",
    "- qnli\n",
    "- rte\n",
    "- wnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_param = \"cola\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskConfig = namedtuple(\"TaskConfig\", [\"sentence_type\", \"class_type\", \"num_classes\", \"col_names\"])\n",
    "\n",
    "task_configs = {\n",
    "    \"cola\": TaskConfig(\"one\", \"BC\", 1, ['sentence']),\n",
    "    \"sst2\": TaskConfig(\"one\", \"BC\", 1, ['sentence']),\n",
    "    \"mrpc\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "    \"stsb\": TaskConfig(\"two\", \"R\", 1, ['sentence1', 'sentence2']),\n",
    "    \"qqp\": TaskConfig(\"two\", \"BC\", 1, ['question1', 'question2']),\n",
    "    \"mnli_matched\": TaskConfig(\"two\", \"MC\", 3, ['premise', 'hypothesis']),\n",
    "    \"mnli_mismatched\": TaskConfig(\"two\", \"MC\", 3, ['premise', 'hypothesis']),\n",
    "    \"qnli\": TaskConfig(\"two\", \"BC\", 1, ['question', 'sentence']),\n",
    "    \"rte\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "    \"wnli\": TaskConfig(\"two\", \"BC\", 1, ['sentence1', 'sentence2']),\n",
    "}\n",
    "\n",
    "task_config = task_configs[task_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if task_param == \"mnli_matched\": \n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_matched\"\n",
    "    test_key = \"test_matched\"\n",
    "elif task_param == \"mnli_mismatched\":\n",
    "    data = load_dataset(\"glue\", \"mnli\") \n",
    "    val_key = \"validation_mismatched\"\n",
    "    test_key = \"test_mismatched\"\n",
    "else:\n",
    "    data = load_dataset(\"glue\", task_param)\n",
    "    val_key = \"validation\"\n",
    "    test_key = \"test\"\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ba35fdbfaf4bdfa539f628996ffcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a36a53ae834c7e87834c292c8dae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc8d0af8d2246ef929cab86694825fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len=512\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[task_config.col_names[0]],\n",
    "                     add_special_tokens=True,\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "def tokenize_double(examples):\n",
    "    return tokenizer(examples[task_config.col_names[0]],\n",
    "                     examples[task_config.col_names[1]],\n",
    "                     add_special_tokens=True,\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "data = data.map(tokenize, batched=True)\n",
    "data = data.rename_column(\"label\", \"labels\")\n",
    "data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import BnConfig\n",
    "from adapters import AutoAdapterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=BnConfig(mh_adapter=True,\n",
    "                output_adapter=True,\n",
    "                reduction_factor=2,\n",
    "                non_linearity=\"relu\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoAdapterModel.from_pretrained('distilroberta-base', config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_classification_head(task_param, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters.training import AdapterArguments\n",
    "adaptargs = AdapterArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task adapter - only add if not existing\n",
    "if task_param not in model.adapters_config:\n",
    "    # resolve the adapter config\n",
    "    adapter_config = config.load(adaptargs.adapter_config)\n",
    "    # add a new adapter\n",
    "    model.add_adapter(task_param, config=adapter_config)\n",
    "# Enable adapter training\n",
    "model.train_adapter(task_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_adapters(task_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import TrainingArguments, EvalPrediction\n",
    "from adapters import AdapterTrainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=3e-4,\n",
    "    max_steps=10000,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=1000,\n",
    "    output_dir=\"adapter-roberta-base-amazon-polarity\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "  preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "  return {\"acc\": (preds == eval_pred.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"test\"],\n",
    "    compute_metrics=compute_accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/models/roberta/adapter_model.py\", line 69, in forward\n    outputs, context = self.roberta(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/context.py\", line 116, in wrapper_func\n    results = f(self, *args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/model_mixin.py\", line 1270, in forward\n    return super().forward(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 835, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 524, in forward\n    layer_outputs = layer_module(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n    result = forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 455, in forward\n    layer_output = apply_chunking_to_forward(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/pytorch_utils.py\", line 241, in apply_chunking_to_forward\n    return forward_fn(*input_tensors)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 468, in feed_forward_chunk\n    layer_output = self.output(intermediate_output, attention_output)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/models/roberta/modeling_roberta.py\", line 159, in forward\n    hidden_states = self.bottleneck_layer_forward(hidden_states, input_tensor, self.LayerNorm)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 348, in bottleneck_layer_forward\n    state = self.compose(adapter_setup, state)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/adapter_layer_base.py\", line 472, in compose\n    state = composition_func(adapter_setup, state, lvl=0)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/adapter_layer_base.py\", line 308, in compose_stack\n    state = self.compose_single(adapter_stack_layer, state, lvl=lvl + 1)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 230, in compose_single\n    layer_output = adapter_layer(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/modeling.py\", line 172, in forward\n    down = self.adapter_down(x)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n    input = module(input)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:89\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     87\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 89\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/fast/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/models/roberta/adapter_model.py\", line 69, in forward\n    outputs, context = self.roberta(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/context.py\", line 116, in wrapper_func\n    results = f(self, *args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/model_mixin.py\", line 1270, in forward\n    return super().forward(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 835, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 524, in forward\n    layer_outputs = layer_module(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n    result = forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 455, in forward\n    layer_output = apply_chunking_to_forward(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/pytorch_utils.py\", line 241, in apply_chunking_to_forward\n    return forward_fn(*input_tensors)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 468, in feed_forward_chunk\n    layer_output = self.output(intermediate_output, attention_output)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/models/roberta/modeling_roberta.py\", line 159, in forward\n    hidden_states = self.bottleneck_layer_forward(hidden_states, input_tensor, self.LayerNorm)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 348, in bottleneck_layer_forward\n    state = self.compose(adapter_setup, state)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/adapter_layer_base.py\", line 472, in compose\n    state = composition_func(adapter_setup, state, lvl=0)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/adapter_layer_base.py\", line 308, in compose_stack\n    state = self.compose_single(adapter_stack_layer, state, lvl=lvl + 1)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 230, in compose_single\n    layer_output = adapter_layer(\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/adapters/methods/modeling.py\", line 172, in forward\n    down = self.adapter_down(x)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n    input = module(input)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mvq0861/miniconda3/envs/fast/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Function to merge datasets\n",
    "def clean_dataset(inputs, split):\n",
    "    common_columns_to_remove = {'sentence', 'sentence1', 'sentence2', 'label', 'question1', 'question2', 'premise', 'hypothesis', 'question'}\n",
    "\n",
    "    if isinstance(inputs, list):\n",
    "        dataframe = [ds[split].to_pandas() for ds in inputs]\n",
    "        dataframe = [df.drop(columns=common_columns_to_remove, errors='ignore') for df in dataframe]\n",
    "        cleaned_df = dataframe[0]\n",
    "        for df in dataframe[1:]:\n",
    "            cleaned_df = pd.merge(cleaned_df, df, on='idx', how='inner')\n",
    "    else:\n",
    "        dataframe = inputs[split].to_pandas()\n",
    "        cleaned_df = dataframe.drop(columns=common_columns_to_remove, errors='ignore')\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        # Exclude 'idx' column and convert others to tensors\n",
    "        self.columns = [col for col in dataframe.columns if col != 'idx']\n",
    "        for col in self.columns:\n",
    "            # Convert to NumPy array first for efficiency\n",
    "            np_array = np.array(dataframe[col].tolist())\n",
    "            setattr(self, col, torch.tensor(np_array, dtype=torch.int64))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve tensors by index for each column\n",
    "        item = {col: getattr(self, col)[idx] for col in self.columns}\n",
    "        return item\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 128\n",
    "\n",
    "if create_dataloader:\n",
    "\n",
    "    # Merge datasets for each split and convert to PyTorch datasets\n",
    "    train_df = clean_dataset(inputs, 'train')\n",
    "    validation_df = clean_dataset(inputs, 'validation')\n",
    "    test_df = clean_dataset(inputs, 'test')\n",
    "\n",
    "    # Create dataset instances\n",
    "    train_dataset = TransformerDataset(train_df)\n",
    "    validation_dataset = TransformerDataset(validation_df)\n",
    "    test_dataset = TransformerDataset(test_df)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(loader, X):\n",
    "    column_names = list(next(iter(loader)).keys())\n",
    "\n",
    "    # Creating pairs of input IDs and attention masks\n",
    "    pairs = []\n",
    "    for name in column_names:\n",
    "        if 'input_ids' in name:\n",
    "            mask_name = name.replace('input_ids', 'attention_mask')\n",
    "            pairs.append((name, mask_name))\n",
    "\n",
    "    # Loop over each pair of input ID and attention mask\n",
    "    for input_id_name, mask_name in pairs:\n",
    "        embedding = []\n",
    "        tqdm.write(f\"{input_id_name} {mask_name}\")\n",
    "        # time.sleep(0.2) # tqdm prints weird without slight time delay - delay subtracted when calculating embedding time\n",
    "    \n",
    "        for input_embedding in tqdm(loader):\n",
    "            # Move batch to device\n",
    "            model.eval()\n",
    "            input_embedding = {key: value.to(device) for key, value in input_embedding.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_embedding[input_id_name], attention_mask=input_embedding[mask_name])\n",
    "\n",
    "                if \"cls\" in input_id_name:\n",
    "                    embed = extract_cls_embeddings(outputs)\n",
    "                elif \"meanpool\" in input_id_name:\n",
    "                    embed = mean_pooling(outputs, input_embedding[mask_name])\n",
    "\n",
    "            embedding.append(embed.cpu().numpy())\n",
    "\n",
    "        id = embedding_param.index(input_id_name.split(\"_input_ids\")[0])\n",
    "        # print(id)\n",
    "        if \"2\" in input_id_name:\n",
    "            U, V = X[id], np.concatenate(embedding, axis=0)\n",
    "            X[id] = np.hstack([U, V])\n",
    "            # print(X[id])\n",
    "        else:\n",
    "            X[id] = np.concatenate(embedding, axis=0)\n",
    "            # print(X[id])\n",
    "\n",
    "def compute_sentence(sentences):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        batch_embeddings = sentence_model.encode(batch_sentences)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.concatenate(embeddings, axis=0)\n",
    "\n",
    "print(\"Embedding: Using default time tracking\")\n",
    "# Track time\n",
    "start_time = time.time()\n",
    "\n",
    "if create_dataloader: # Compute CLS/Meanpool embeddings\n",
    "    compute_embeddings(train_loader, X_train)\n",
    "    compute_embeddings(validation_loader, X_val)\n",
    "    compute_embeddings(test_loader, X_test)\n",
    "if create_sentence: # Compute Sentence embeddings\n",
    "    if \"sentence_single\" in embedding_param:\n",
    "        id = embedding_param.index(\"sentence_single\")\n",
    "        U_train, V_train = compute_sentence(data[\"train\"][task_config.col_names[0]]), compute_sentence(data[\"train\"][task_config.col_names[1]])\n",
    "        U_val, V_val = compute_sentence(data[\"validation\"][task_config.col_names[0]]), compute_sentence(data[\"validation\"][task_config.col_names[1]])\n",
    "        U_test, V_test = compute_sentence(data[\"test\"][task_config.col_names[0]]), compute_sentence(data[\"test\"][task_config.col_names[1]])\n",
    "\n",
    "        X_train[id] = np.hstack([U_train, V_train])\n",
    "        X_val[id] = np.hstack([U_val, V_val])\n",
    "        X_test[id] = np.hstack([U_test, V_test])\n",
    "\n",
    "    elif \"sentence\" in embedding_param:\n",
    "        id = embedding_param.index(\"sentence\")\n",
    "        X_train[id] = compute_sentence(data[\"train\"][task_config.col_names[0]])\n",
    "        X_val[id] = compute_sentence(data[\"validation\"][task_config.col_names[0]])\n",
    "        X_test[id] = compute_sentence(data[\"test\"][task_config.col_names[0]])\n",
    "\n",
    "embedding_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embeddings to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in embedding_tracker:\n",
    "\n",
    "    cache_path = pathlib.Path(f\"./cache/{embedding_param[id]}/{task_param}\")\n",
    "    cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_names = ['X_train', 'X_val', 'X_test']\n",
    "    paths = [pathlib.Path(cache_path / f\"{f}_{model_param}.npy\") for f in file_names]\n",
    "\n",
    "    with open(paths[0], 'wb') as X_train_file:\n",
    "        np.save(X_train_file, X_train[id])\n",
    "    with open(paths[1], 'wb') as X_val_file:\n",
    "        np.save(X_val_file, X_val[id])\n",
    "    with open(paths[2], 'wb') as X_test_file:\n",
    "        np.save(X_test_file, X_test[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_val = np.concatenate(X_val, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape  : {X_val.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(embeddings, column_ids, embedding_size, is_UV, is_diff, is_mult):\n",
    "    '''\n",
    "    Add embeddings at specific column_ids. For example, for the matrix\n",
    "    [Z1, Z2, U1, V1, Z3, U2, V2], if we want to replace this with:\n",
    "    [Z1, Z2, U1 - V1, Z3, U2, V2, U2 - V2, U2 * V2], we provide the parameters:\n",
    "    is_UV = [False, True] : U1, V1 are NOT kept, but U2, V2 are kept\n",
    "    is_diff = [True, True] : both U1 - V1 and U2 - V2 are added\n",
    "    is_mult = [False, True] : U1 * V1 is not included, U2 * V2 is included\n",
    "\n",
    "    Args:\n",
    "        embeddings : original matrix to replace\n",
    "        column_ids : location of Ux (we assume Vx immedeately follows Ux), \n",
    "                     for the above example, we would provide column_ids = [2, 5].\n",
    "                     If you DO NOT want to replace a certain Ux, simply don't include its id in column_ids\n",
    "        is_UV : should Ux, Vx be included\n",
    "        is_diff : should Ux - Vx be included\n",
    "        is_mult : should Ux * Vx be included\n",
    "    '''\n",
    "\n",
    "    id_delta = 0 # keep track of changes to embedding inserts/deletions\n",
    "    for id, column_id in enumerate(column_ids):\n",
    "\n",
    "        if id>0:\n",
    "            if not is_UV[id-1]:\n",
    "                id_delta -= 2\n",
    "            if is_diff[id-1]:\n",
    "                id_delta += 1\n",
    "            if is_mult[id-1]:\n",
    "                id_delta += 1\n",
    "\n",
    "        start_id = (column_id + id_delta) * embedding_size\n",
    "        U_id = start_id + embedding_size\n",
    "        V_id = start_id + (2*embedding_size)\n",
    "\n",
    "        U = embeddings[:, start_id:U_id]\n",
    "        V = embeddings[:, U_id:V_id]\n",
    "\n",
    "        if is_diff[id] and not is_mult[id]:\n",
    "            new_embeddings = (U - V)\n",
    "        elif not is_diff[id] and is_mult[id]:\n",
    "            new_embeddings = U * V\n",
    "        else: # both\n",
    "            new_embeddings = np.hstack([(U - V), (U * V)])\n",
    "\n",
    "        if is_UV[id]:                  \n",
    "            embeddings = np.hstack([\n",
    "                embeddings[:, :V_id],       # Part of original matrix before replacement\n",
    "                new_embeddings,             # New embeddings to insert\n",
    "                embeddings[:, V_id:]        # Part of original matrix after replacement\n",
    "            ])\n",
    "        else:\n",
    "            embeddings = np.hstack([\n",
    "                embeddings[:, :start_id],   # Part of original matrix before replacement\n",
    "                new_embeddings,             # New embeddings to insert\n",
    "                embeddings[:, V_id:]        # Part of original matrix after replacement\n",
    "            ])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Choose ids of (Ux, Vx) to alter embeddings\n",
    "column_ids = [] if task_config.sentence_type == \"one\" else [0]\n",
    "######################\n",
    "\n",
    "if column_ids:\n",
    "    f = lambda embeddings : add_embeddings(embeddings=embeddings, column_ids=column_ids, embedding_size=768, \n",
    "                                           is_UV=[False], is_diff=[True], is_mult=[False])\n",
    "\n",
    "    X_train_computed = f(embeddings=X_train)\n",
    "    X_val_computed = f(embeddings=X_val)\n",
    "    X_test_computed = f(embeddings=X_test)\n",
    "else:\n",
    "    X_train_computed = X_train\n",
    "    X_val_computed = X_val\n",
    "    X_test_computed = X_test\n",
    "    \n",
    "print(X_train_computed.shape)\n",
    "print(X_val_computed.shape)\n",
    "print(X_test_computed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_computed.shape[1]\n",
    "\n",
    "param_grid = {\n",
    "    'max_epochs': [50],\n",
    "    'batch_size': [32],\n",
    "    'learning_rate': [0.001],\n",
    "    'category': ['MC'],\n",
    "    'norm': [False],\n",
    "    'input_size': [768],\n",
    "    'layer_size': [768],\n",
    "    'num_classes': [3],\n",
    "    'num_layers': [1],\n",
    "    'weight_decay': [0.0001],\n",
    "    'patience': [3],\n",
    "    'min_delta': [0],\n",
    "}\n",
    "\n",
    "# default overrides\n",
    "param_grid['verbose'] = [True]\n",
    "param_grid['device'] = [device_name]\n",
    "\n",
    "# Create a list of all combinations of hyperparameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "print(f\"{len(all_params)} hyperparameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "# Setup for logging\n",
    "console_output_filename = f'./output/{\"_\".join(embedding_param[0])}_{task_param}_console_output.txt'\n",
    "\n",
    "with open(console_output_filename, 'a') as logfile:\n",
    "    logfile.write('\\n\\nBEGIN TRAINING LOOP\\n\\n')\n",
    "\n",
    "# Setup for saving results\n",
    "results_folder = pathlib.Path(f\"results/{embedding_param[0]}/{task_param}\")\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_file_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = results_folder / f\"val_{save_file_id}_{model_param}.csv\"\n",
    "\n",
    "# different metrics are recorded for classification vs regression tasks\n",
    "if task_config.class_type in [\"BC\", \"MC\"]:\n",
    "    metric_types = ['mcc', 'f1', 'accuracy']\n",
    "elif task_config.class_type == \"R\":\n",
    "    metric_types = ['pearson', 'spearman']\n",
    "\n",
    "with open(results_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    header = metric_types + ['num_epochs', 'training time / epoch', 'embedding time', 'training energy / epoch', 'embedding energy'] + list(all_params[0].keys())\n",
    "    writer.writerow(header)\n",
    "print(f\"saving results to ./{results_file}\")\n",
    "metric_types += [\"epoch\"]\n",
    "# Saves best accuracy for progress bar display\n",
    "display_best = float(\"-inf\")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "bar = tqdm(enumerate(all_params), total=len(all_params))\n",
    "for i, params in bar:\n",
    "    # Formatting params to display\n",
    "    print_params = params.copy()\n",
    "    for param in ['category', 'device']:\n",
    "        del print_params[param]\n",
    "        \n",
    "    # reset torch so that results are consistent\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Initialize the model with current set of hyperparameters\n",
    "    feed_forward = FeedForward(**params)\n",
    "\n",
    "    metrics, train_times_per_epoch, energy_per_epoch = feed_forward.fit(X_train_computed,\n",
    "                                                                        Y_train,\n",
    "                                                                        X_val_computed,\n",
    "                                                                        Y_val)\n",
    "    \n",
    "    # Log average training time per epoch for current parameter set\n",
    "    # Note: FFN frequently stops early\n",
    "    training_time = np.mean(train_times_per_epoch)\n",
    "    training_energy = np.mean(energy_per_epoch) \n",
    "    # Compute energy for embedding generation\n",
    "    embedding_energy = get_energy(embedding_time, device) # This method effectively just computes energy for a given time\n",
    "\n",
    "    metric_vals = [metrics[mt] for mt in metric_types]\n",
    "    \n",
    "    # displaying results in progress bar\n",
    "    display_recent = metrics[\"pearson\" if task_config.class_type == \"R\" else \"accuracy\"]\n",
    "    display_best = max(display_best, display_recent)\n",
    "    bar.set_description(f\"Best: {display_best:.5f}, Last: {display_recent:.5f}\")\n",
    "\n",
    "    # Write stats to log file\n",
    "    with open(console_output_filename, 'a') as logfile:\n",
    "        logfile.write(f\"\\n\\nTraining with parameters:\\n{print_params}\")\n",
    "        logfile.write(f\"\\nEarly stopped on epoch: {metrics['epoch']}\")\n",
    "        for name, val in zip(metric_types, metric_vals):\n",
    "            logfile.write(f\"\\nValidation {name}: {val}\")\n",
    "        logfile.write(f\"\\nTraining time      : {training_time}\") \n",
    "        logfile.write(f\"\\nEmbedding time     : {embedding_time}\") \n",
    "        logfile.write(f\"\\nTraining energy    : {training_energy}\") \n",
    "        logfile.write(f\"\\nEmbedding energy   : {embedding_energy}\") \n",
    "    # Write to results csv\n",
    "    with open(results_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        row = metric_vals + [training_time, embedding_time, training_energy, embedding_energy] + list(params.values())\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(results_file)\n",
    "if task_config.class_type in [\"BC\", \"MC\"]:\n",
    "    print_metric = \"accuracy\"\n",
    "elif task_config.class_type == \"R\":\n",
    "    print_metric = \"pearson\"\n",
    "\n",
    "best = results_df[print_metric].max()\n",
    "best_row = results_df[results_df[print_metric] == best]\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Eval on Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set best hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_computed.shape[1]\n",
    "\n",
    "# best hyperparameter combination\n",
    "param_grid = {\n",
    "    'max_epochs': [7],\n",
    "    'batch_size': [512],\n",
    "    'learning_rate': [0.01],\n",
    "    'category': ['R'],\n",
    "    'norm': [False],\n",
    "    'input_size': [768],\n",
    "    'layer_size': [768],\n",
    "    'num_classes': [1],\n",
    "    'num_layers': [5],\n",
    "    'weight_decay': [0.0001],\n",
    "    'patience': [5],\n",
    "    'min_delta': [0],\n",
    "    'device': ['mps'],\n",
    "    'verbose': [False]\n",
    "}\n",
    "\n",
    "# Create a list of all combinations of hyperparameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "print(f\"{len(all_params)} hyperparameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "# Setup for logging\n",
    "console_output_filename = f'./output/{\"_\".join(embedding_param[0])}_{task_param}_console_output.txt'\n",
    "\n",
    "with open(console_output_filename, 'a') as logfile:\n",
    "    logfile.write('\\n\\nBEGIN FINAL TRAINING LOOP\\n\\n')\n",
    "\n",
    "# Setup for saving results\n",
    "results_folder = pathlib.Path(f\"results/{embedding_param[0]}/{task_param}\")\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_file_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "test_results_file = results_folder / f\"test_{save_file_id}_{model_param}.csv\"\n",
    "test_y_pred_file = results_folder / f\"y_pred_{save_file_id}_{model_param}.tsv\"\n",
    "\n",
    "# different metrics are recorded for classification vs regression tasks\n",
    "if task_config.class_type in [\"BC\", \"MC\"]:\n",
    "    metric_types = ['mcc', 'f1', 'accuracy']\n",
    "elif task_config.class_type == \"R\":\n",
    "    metric_types = ['pearson', 'spearman']\n",
    "\n",
    "with open(test_results_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    header = metric_types + ['training time / epoch', 'embedding time', 'training energy / epoch', 'embedding energy'] + list(all_params[0].keys())\n",
    "    writer.writerow(header)\n",
    "print(f\"saving results to ./{test_results_file}\")\n",
    "# Saves best accuracy for progress bar display\n",
    "display_best = float(\"-inf\")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "bar = tqdm(enumerate(all_params), total=len(all_params))\n",
    "for i, params in bar:\n",
    "    # Formatting params to display\n",
    "    print_params = params.copy()\n",
    "    for param in ['category', 'device']:\n",
    "        del print_params[param]\n",
    "        \n",
    "    # reset torch so that results are consistent\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Initialize the model with current set of hyperparameters\n",
    "    feed_forward = FeedForward(**params)\n",
    "\n",
    "    _, train_times_per_epoch, energy_per_epoch = feed_forward.fit(X_train_computed,\n",
    "                                                                Y_train,\n",
    "                                                                X_val_computed,\n",
    "                                                                Y_val)\n",
    "    \n",
    "    metrics = feed_forward._validate(X_test_computed, Y_test, return_predictions=True)\n",
    "\n",
    "    y_pred = metrics[\"predictions\"]\n",
    "    del metrics[\"predictions\"]\n",
    "\n",
    "    y_pred_df = pd.DataFrame(y_pred, columns=[\"prediction\"])\n",
    "    y_pred_df[\"index\"] = y_pred_df.index\n",
    "    y_pred_df = y_pred_df[[\"index\", \"prediction\"]]\n",
    "    y_pred_df.to_csv(test_y_pred_file, sep='\\t', index=False, header=True)\n",
    "    print(f\"saving predictions to ./{test_y_pred_file}\")\n",
    "    \n",
    "    # Log average training time per epoch for current parameter set\n",
    "    # Note: FFN frequently stops early\n",
    "    training_time = np.mean(train_times_per_epoch)\n",
    "    training_energy = np.mean(energy_per_epoch) \n",
    "    # Compute energy for embedding generation\n",
    "    embedding_energy = get_energy(embedding_time, device) # This method effectively just computes energy for a given time\n",
    "\n",
    "    metric_vals = [metrics[mt] for mt in metric_types]\n",
    "    \n",
    "    # displaying results in progress bar\n",
    "    display_recent = metrics[\"pearson\" if task_config.class_type == \"R\" else \"accuracy\"]\n",
    "    display_best = max(display_best, display_recent)\n",
    "    bar.set_description(f\"Best: {display_best:.5f}, Last: {display_recent:.5f}\")\n",
    "\n",
    "    # Write stats to log file\n",
    "    with open(console_output_filename, 'a') as logfile:\n",
    "        logfile.write(f\"\\n\\nTraining with parameters:\\n{print_params}\")\n",
    "        for name, val in zip(metric_types, metric_vals):\n",
    "            logfile.write(f\"\\nValidation {name}: {val}\")\n",
    "        logfile.write(f\"\\nTraining time      : {training_time}\")\n",
    "        logfile.write(f\"\\nEmbedding time     : {embedding_time}\") \n",
    "        logfile.write(f\"\\nTraining energy    : {training_energy}\") \n",
    "        logfile.write(f\"\\nEmbedding energy   : {embedding_energy}\") \n",
    "    # Write to results csv\n",
    "    with open(test_results_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        row = metric_vals + [training_time, embedding_time, training_energy, embedding_energy] + list(params.values())\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(test_results_file)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
